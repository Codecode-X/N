# CLIP Glasses：为CLIP戴上“眼镜”，使其具拥有辨别肯定和否定的能力

*在一次灯光璀璨的音乐节现场，一位观众戴上了一副看似普通的眼镜，瞬间，整个世界在他眼中化作了流动的彩虹。他望向舞台上闪烁的聚光灯，每一道白光仿佛裂解成无数色彩斑斓的丝带，随着节奏在空气中跳动。这并非幻觉，而是**光栅眼镜**带来的真实视觉体验。光栅眼镜是一种利用光的衍射原理制造色散效果的工具，常用于娱乐、教学与科学演示等场合。它的镜片上覆盖着具有高度规律排列的微细刻线，称为光栅，当白光通过这些刻线时，不同波长的光会发生不同角度的衍射，从而在观察者眼中呈现出多彩的光谱。*

< 引入介绍当前CLIP对于否定信息无法辨别的“色盲”现象 > .....

**外科手术式的创伤性疗法：**目前的现有工作主要通过外科手术式的创伤性疗法帮助CLIP矫正“色盲”，即通过新搜集或合成的包含更多否定内容的新数据集，对CLIP的文本编码器进行微调训练，从而使CLIP恢复对否定信息的判断能力。但这种方法具有较高的风险和成本，具体来说，若微调数据集与原始预训练数据分布差异较大或覆盖场景有限，微调将会存在较大的风险覆盖CLIP预训练阶段学习到的通用表征能力，过拟合于微调数据集，甚至导致灾难性遗忘，同时提出新的符合要求的数据集和微调也会带来较高的数据标注成本及计算资源消耗。

**CLIP Glasses：**为了能够零风险且低成本的让CLIP具备辨别肯定和否定的能力，我们为CLIP设计了一款“眼镜”，即Glasses模块，类似日常生活中人类所佩戴的眼镜，其也是由 Lenses（镜片） 和 Frames（镜架）两个部件组成。其中Lenses将一段原始文本通过“光栅化”处理“衍射”为两类文本，即肯定文本和否定文本。而Frames则通过调节CLIP模型接收和处理该两类文本的行为，对两种文本施加完全相反的相似度计算方式（例如在图像检索任务中，目标图像应与匹配文本的肯定部分相似度尽可能高，与否定部分相似度尽可能低；在MCQ任务中，目标文本的肯定部分与图像的相似度尽可能高，否定部分则相似度尽可能低），使得CLIP能够在拥有分辨能力的同时不过度强调否定样本导致能力退化（例如 [?] 只是单纯地远离否定内容，而并非真正理解否定）。

---

# CLIPGlasses

CLIPGlasses 由 Lens 和 Fram 两个组件组成。

### 组件1：Lens of Glasses

#### 1. 否定信息是否真的丢失了？没有丢失

验证CLIP文本编码器的最终输出特征 `h` 是否因过度抽象化丢失了否定逻辑信息。

##### 否定-肯定对数据集构建

- 否定句：`"A sofa with no cat"`
- 肯定句：`"A sofa with a cat"`
- **特点**：语义相似，仅否定词差异。

##### 实验1：二分类任务验证

​	训练分类器判断句子是否含否定词（二分类）。

* **数据集**：
  - **正样本**：所有否定句（如“没有猫的沙发”）。
  - **负样本**：所有肯定句（如“有猫的沙发”）。
  - **注意**：需确保正负样本的语义相似度匹配（避免分类器仅依赖语义差异）。
* **模型**：使用逻辑回归（Logistic Regression），输入为CLIP特征 `h`。
* **评估指标**：准确率（Accuracy）、F1分数。
  - 若准确率接近随机猜测（50%）：说明 `h` 中无否定信息。
  - 若准确率显著高于随机：说明 `h` 保留否定信息。

#####  实验2：注意力权重可视化

​	观察CLIP文本编码器是否关注否定词（如“没有”）。

* 提取每一层的注意力权重，并可视化**注意力热力图**。
  * 若否定词（“没有”）对主语（“猫”）有高注意力权重：说明模型捕捉到否定逻辑。
  * 若注意力分散或无聚焦：说明否定信息未被显式编码。

##### 实验3：特征空间可视化

​	使用t-SNE将高维特征 `h` 降维至2D，绘制分布图。

<img src="notes/images/CLIP Glasses：为CLIP戴上“眼镜”，使其具拥有辨别肯定和否定的能力/image-20250417141648352.png" alt="image-20250417141648352" style="zoom: 33%;" /><img src="notes/images/CLIP Glasses：为CLIP戴上“眼镜”，使其具拥有辨别肯定和否定的能力/image-20250417152437859.png" alt="image-20250417152437859" style="zoom:33%;" />

* 若否定句（neg）和肯定句（pos）在特征空间中混叠：说明否定信息丢失。
* 若否定句（neg）与语义无关句（unrelated）在特征空间中混叠：说明CLIP完全无法区分否定逻辑。

-----

### 模块设计

#### **1. 双路正交投影网络**

**核心思想**：通过正交约束的投影空间，强制分离肯定/否定语义，同时保留CLIP的语义空间结构。

- **结构设计**：

  - **共享特征分解层**：**轻量级MLP**将CLIP特征 `h` 分解为两个**正交基向量 `u`（肯定相关）和 `v`（否定相关）**。

  - **动态门控融合**：基于输入特征 `h` 的语义强度，动态融合正交基向量生成最终特征：
    $$
    h_{pos} = \alpha \cdot u + (1-\alpha) \cdot h_{original}
    $$

    $$
    h_{neg} = \beta \cdot v + (1-\beta) \cdot h_{original}
    $$

    其中 $\alpha$, $\beta$ 由门控网络生成，用于控制语义修正强度。

    $$
    [\alpha, \beta] = \sigma(\text{MLP}(h))
    $$


- **创新点**：

  - **正交基约束**：强制 `u` 和 `v` 在特征空间正交，物理上分离两种语义。
  - **残差连接**：残差连接设计保留CLIP原有优势，在非否定场景下自动退化为原始特征

---

#### **2. 损失函数**

**核心思想**：通过对比学习对齐目标特征，同时引入正交约束和语义纯度约束。

**语义对齐损失**：
$$
\mathcal{L}_{align} = \frac{1}{2} \left[ 1 - \cos(h_{pos}, l_{pos}) + 1 - \cos(h_{neg}, l_{neg}) \right]
$$
**正交对抗损失（当前策略）**：
$$
\mathcal{L}_{ortho} = \max(0, \cos(h_{pos}, h_{neg})^2 - \epsilon)
$$

==**非语义维度正交损失（TODO）**：==

> ✅ 意义：我们只约束**与标签无关的部分**之间保持正交，让模型保留必要的语义方向而在其他方向区分样本。

定义“语义核心方向”为单位向量：
$$
c_{pos} = \frac{l_{pos}}{\|l_{pos}\|}, \quad c_{neg} = \frac{l_{neg}}{\|l_{neg}\|}
$$
计算目标特征在非语义方向上的正交投影：
$$
\begin{aligned} \tilde{h}_{pos} &= h_{pos} - \langle h_{pos}, c_{pos} \rangle c_{pos} \\ \tilde{h}_{neg} &= h_{neg} - \langle h_{neg}, c_{neg} \rangle c_{neg} \end{aligned}
$$
然后对这两个投影计算相似度并约束正交性：
$$
\mathcal{L}_{ortho} = \max(0, \cos(\tilde{h}_{pos}, \tilde{h}_{neg})^2 - \epsilon)
$$
**总损失**：
$$
\mathcal{L}_{total} = \lambda_1 \mathcal{L}_{align} + \lambda_2 \mathcal{L}_{ortho}
$$

$$
\lambda_2(t) = \lambda_{2}^{max} \cdot (1 - e^{-5t/T})
$$

> *T* 为总训练步数，初期 $λ_2$ 较低，后期增强正交约束。详细见 两阶段训练策略

---

#### **3. 动态语义感知训练**

**核心思想**：根据样本难度自适应调整学习目标，对困难样本（初始相似度低）赋予更高权重，缓解简单/困难样本的不平衡。

- **实现方法**：

  - **难度感知加权**：对每个样本计算初始相似度 $s = \cos(h, l_{pos}) + \cos(h, l_{neg})$，定义权重：
    $$
    w = \frac{2}{1 + e^{-k(s - s_0)}} \quad (k>0)
    $$

---

#### **训练流程**

1. **两阶段训练策略**：

   - **阶段1**（粗对齐）：仅使用 $\mathcal{L}_{align}$ 建立初步关联
   - **阶段2**（精细化）：逐步引入 $\mathcal{L}_{ortho}$ 和 $\mathcal{L}_{purity}$
   - **自动阶段切换**：当 $\mathcal{L}_{align}$ 连续3个epoch下降<1%时，进入阶段2。
   - **学习率热重启**：阶段切换时重置优化器学习率至初始值，避免陷入局部最优

2. **动态阈值调整**：

   - 根据训练进度自动调整**正交约束阈值 $\epsilon$**：
     $$
     \epsilon(t) = \epsilon_{min} + (\epsilon_{max} - \epsilon_{min}) \cdot e^{-t/\tau}
     $$
     初始宽松（$\epsilon_{max}=0.5$），逐步收紧至目标值（$\epsilon_{min}=0.1$），实现逐步增大正交约束力度。

---

**总结：**该设计通过**正交空间投影**与**动态语义门控**的协同作用，在保持轻量化的同时实现细粒度语义解耦，其创新点在于将几何约束（正交性）与数据驱动学习（对比损失）有机结合，为CLIP的否定理解问题提供了新的解决范式。

----



## 组件2：Frame of Glasses

### 1. **鲁棒差分对比学习（RDCL）**

#### **标准化差分匹配得分**  

对图像特征 $v \in \mathbb{R}^d$ 和文本特征 $h_{pos}, h_{neg}$，定义：  
$$
S(v) = \frac{\cos(v, h_{pos})}{\tau_{pos}} - \lambda \cdot \frac{\cos(v, h_{neg})}{\tau_{neg}}
$$

- $\tau_{pos}, \tau_{neg}$：温度系数（可学习标量）  
- $\lambda$：动态惩罚权重（由 $h_{neg}$ 置信度决定，见后）

#### **动态惩罚权重**  

$$
\lambda = \lambda_0 \cdot \sigma\left( \text{MLP}(h_{neg}) \right)
$$

- $\lambda_0$：基础惩罚强度（超参数，建议0.5-1.0）  
- $\sigma(\cdot)$：Sigmoid函数，限制 $\lambda \in (0, \lambda_0)$  
- MLP：单隐藏层网络（输入维度$d$, 输出维度1）

#### **匹配度计算**：

每个候选描述计算得分 $S_0, S_1, S_2, S_3$
$$
S_i = \frac{\cos(h_{img}, h_{pos}^{(i)})}{\tau_{pos}} - \lambda^{(i)} \cdot \frac{\cos(h_{img}, h_{neg}^{(i)})}{\tau_{neg}}
$$

#### **损失函数设计**

* **交叉熵损失**：
  $$
  \mathcal{L}_{\text{CE}} = -\sum_{i=0}^3 y_i \log\left(\frac{e^{S_i}}{\sum_j e^{S_j}}\right)
  $$
  
* **正则化项**：
  $$
  \mathcal{L}_{\text{reg}} = 0.05 \cdot \|\text{MLP}(h_{neg})\|_2^2
  $$

#### **训练流程**

* **训练参数：**(总参数量 <1K)  

  * MLP参数

  * $\tau_{pos}$, $\tau_{neg}$, $\lambda_0$  

* **训练数据集**: 

  * COCO_val_mcq_llama3.1_rephrased.csv  ==待换成更大的合成数据集==

  * **特征预提取**（离线完成，仅需一次）：

    * 对每个候选描述 $c_i (i=0,1,2,3)$：使用 CLIP-GlassesLens 提取 $h_{pos}^{(i)}, h_{neg}^{(i)}$

    * 对图像 $v$：使用原始 CLIP 提取 $h_{img}$

  * **标签构建**：
    * 对每个样本生成 One-Hot 标签向量 $y \in \{0,1\}^4$（正确选项为1）

* **训练策略**
  * 余弦退火训练
